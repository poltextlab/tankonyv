
@article{grimmer2013text,
	title = {Text as {Data}: {The} {Promise} and {Pitfalls} of {Automatic} {Content} {Analysis} {Methods} for {Political} {Texts}},
	volume = {21},
	doi = {10.1093/pan/mps028},
	number = {3},
	journal = {Political Analysis},
	author = {Grimmer, Justin and Stewart, Brandon M},
	year = {2013},
	pages = {267--297},
	annote = {tex.ids= grimmerTextDataPromise2013 publisher: Cambridge University Press},
}

@article{wickham2014tidy,
	title = {Tidy {Data}},
	volume = {59},
	url = {https://www.jstatsoft.org/article/view/v059i10},
	doi = {10.18637/jss.v059.i10},
	number = {10},
	journal = {Journal of Statistical Software},
	author = {Wickham, Hadley},
	year = {2014},
	pages = {1--23},
}

@book{wickham2016r,
	address = {Sebastopol, CA},
	title = {R for {Data} {Science}: {Import}, {Tidy}, {Transform}, {Visualize}, and {Model} {Data}},
	isbn = {978-1-4919-1034-4},
	publisher = {O'Reilly Media, Inc.},
	author = {Wickham, Hadley and Grolemund, Garrett},
	year = {2016},
}

@article{jacobiQuantitativeAnalysisLarge2016,
	title = {Quantitative analysis of large amounts of journalistic texts using topic modelling},
	volume = {4},
	doi = {10.1080/21670811.2015.1093271},
	number = {1},
	journal = {Digital Journalism},
	author = {Jacobi, Carina and Van Atteveldt, Wouter and Welbers, Kasper},
	year = {2015},
	pages = {89--106},
	annote = {Publisher: Taylor \& Francis},
}

@article{bleiLatentDirichletAllocation2003,
	title = {Latent {Dirichlet} {Allocation}},
	volume = {3},
	url = {https://www.jmlr.org/papers/v3/blei03a.html},
	number = {Jan},
	journal = {Journal of Machine Learning Research},
	author = {Blei, David M and Ng, Andrew Y and Jordan, Michael I},
	year = {2003},
	pages = {993--1022},
}

@incollection{burtejinCsoportositasKlaszterezes2016,
	address = {Budapest},
	title = {Csoportosítás ({Klaszterezés})},
	isbn = {978-963-414-229-4},
	booktitle = {Kvantitatív szövegelemzés és szövegbányászat a politikatudományban},
	publisher = {L'Harmattan},
	author = {Burtejin, Zorgit},
	editor = {Sebők, Miklós},
	year = {2016},
	pages = {85--101},
}

@book{tanBevezetesAzAdatbanyaszatba2011,
	title = {Bevezetés az adatbányászatba},
	url = {https://gyires.inf.unideb.hu/KMITT/a04/},
	publisher = {Panem},
	author = {Tan, Pang-Ning and Steinbach, Michael and Kumar, Vipin},
	year = {2011},
}

@book{tikkSzovegbanyaszat2007,
	address = {Budapest},
	title = {Szövegbányászat},
	isbn = {978-963-9664-45-6},
	publisher = {Typotex Kiadó},
	editor = {Tikk, Domonkos},
	year = {2007},
}

@article{young2012affective,
	title = {Affective {News}: {The} {Automated} {Coding} of {Sentiment} in {Political} {Texts}},
	volume = {29},
	doi = {10.1080/10584609.2012.671234},
	number = {2},
	journal = {Political Communication},
	author = {Young, Lori and Soroka, Stuart},
	year = {2012},
	pages = {205--231},
	annote = {Publisher: Taylor \& Francis},
}

@article{griffithsGibbsSamplingGenerative2002,
	title = {Gibbs {Sampling} in the {Generative} {Model} of {Latent} {Dirichlet} {Allocation}},
	url = {https://www.researchgate.net/publication/244198720_Gibbs_Sampling_in_the_Generative_Model_of_Latent_Dirichlet_Allocation},
	author = {Griffiths, Tom},
	year = {2002},
	annote = {tex.ids= griffithsGibbsSamplingGenerative2002a publisher: Citeseer},
}

@inproceedings{phanLearningClassifyShort2008,
	title = {Learning to classify short and sparse text \& web with hidden topics from large-scale data collections},
	doi = {10.1145/1367497.1367510},
	booktitle = {{WWW} '08: {Proceedings} of the 17th international conference on {World} {Wide} {Web}},
	author = {Phan, Xuan-Hieu and Nguyen, Le-Minh and Horiguchi, Susumu},
	year = {2008},
	pages = {91--100},
}

@article{mateEffectCentralBank2021,
	title = {The effect of central bank communication on sovereign bond yields: {The} case of {Hungary}},
	volume = {16},
	issn = {1932-6203},
	shorttitle = {The effect of central bank communication on sovereign bond yields},
	url = {https://dx.plos.org/10.1371/journal.pone.0245515},
	doi = {10.1371/journal.pone.0245515},
	language = {en},
	number = {2},
	urldate = {2021-02-15},
	journal = {PLOS ONE},
	author = {Máté, Ákos and Sebők, Miklós and Barczikay, Tamás},
	editor = {Nath, Hiranya K.},
	month = feb,
	year = {2021},
	pages = {e0245515},
	annote = {tex.ids= mateEffectCentralBank2021a ISBN: 1932-6203 publisher: Public Library of Science San Francisco, CA USA},
}

@article{loughranWhenLiabilityNot2011,
	title = {When {Is} a {Liability} {Not} a {Liability}? {Textual} {Analysis}, {Dictionaries}, and 10-{Ks}},
	volume = {66},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.2010.01625.x},
	doi = {10.1111/j.1540-6261.2010.01625.x},
	number = {1},
	journal = {The Journal of Finance},
	author = {Loughran, Tim and McDonald, Bill},
	year = {2011},
	pages = {35--65},
	annote = {tex.publisher: Wiley Online Library},
}

@article{laver2000estimating,
	title = {Estimating {Policy} {Positions} from {Political} {Texts}},
	volume = {44},
	doi = {10.2307/2669268},
	number = {3},
	journal = {American Journal of Political Science},
	author = {Laver, Michael and Garry, John},
	year = {2000},
	pages = {619--634},
	annote = {Publisher: JSTOR},
}

@book{silge2017text,
	address = {Beijing ; Boston},
	title = {Text {Mining} with {R}: {A} {Tidy} {Approach}},
	isbn = {978-1-4919-8165-8},
	publisher = {O'Reilly Media, Inc.},
	author = {Silge, Julia and Robinson, David},
	year = {2017},
}

@book{russelMestersegesIntelligencia2005,
	address = {Budapest},
	title = {Mesterséges intelligencia modern megközelítésben},
	isbn = {978-963-545-411-2},
	publisher = {Panem},
	author = {Russel, Stuart and Norvig, Peter},
	year = {2005},
}

@inproceedings{arun2010finding,
	title = {On {Finding} the {Natural} {Number} of {Topics} with {Latent} {Dirichlet} {Allocation}: {Some} {Observations}},
	doi = {10.1007/978-3-642-13657-3_43},
	booktitle = {14th {Pacific}-{Asia} {Conference}, {PAKDD} 2010, {Hyderabat}, {India}, {June} 21-24, 2010, {Proceedings}},
	author = {Arun, Rajkumar and Suresh, Venkatasubramaniyan and Madhavan, CE Veni and Murthy, MN Narasimha},
	year = {2010},
	pages = {391--402},
	annote = {tex.organization: Springer},
}

@article{cao2009density,
	title = {A density-based method for adaptive {LDA} model selection},
	volume = {72},
	doi = {10.1016/j.neucom.2008.06.011},
	number = {7-9},
	journal = {Neurocomputing},
	author = {Cao, Juan and Xia, Tian and Li, Jintao and Zhang, Yongdong and Tang, Sheng},
	year = {2009},
	pages = {1775--1781},
	annote = {Publisher: Elsevier},
}

@article{deveaud2014accurate,
	title = {Accurate and effective latent concept modeling for ad hoc information retrieval},
	volume = {17},
	doi = {10.3166/DN.17.1.61-84},
	number = {1},
	journal = {Document numérique},
	author = {Deveaud, Romain and SanJuan, Eric and Bellot, Patrice},
	year = {2014},
	pages = {61--84},
	annote = {Publisher: Lavoisier},
}

@article{griffithsFindingScientificTopics2004,
	title = {Finding scientific topics},
	volume = {101},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.0307752101},
	doi = {10.1073/pnas.0307752101},
	language = {en},
	number = {Supplement 1},
	urldate = {2021-02-23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Griffiths, T. L. and Steyvers, M.},
	month = apr,
	year = {2004},
	pages = {5228--5235},
}

@article{roberts2014structural,
	title = {Structural {Topic} {Models} for {Open}-{Ended} {Survey} {Responses}},
	volume = {58},
	doi = {10.1111/ajps.12103},
	number = {4},
	journal = {American Journal of Political Science},
	author = {Roberts, Margaret E and Stewart, Brandon M and Tingley, Dustin and Lucas, Christopher and Leder-Luis, Jetson and Gadarian, Shana Kushner and Albertson, Bethany and Rand, David G},
	year = {2014},
	pages = {1064--1082},
	annote = {Publisher: Wiley Online Library},
}

@article{mikolov2013efficient,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	doi = {10.48550/arXiv.1301.3781},
	journal = {arXiv preprint arXiv:1301.3781},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	year = {2013},
}

@article{spirlingword,
	title = {Word {Embeddings}: {What} {Works}, {What} {Doesn}’t, and {How} to {Tell} the {Difference} for {Applied} {Research}},
	volume = {84},
	url = {https://polmeth.mit.edu/sites/default/files/documents/Pedro_Rodriguez.pdf},
	doi = {10.1086/715162},
	number = {1},
	journal = {The Journal of Politics},
	author = {Spirling, Arthur and Rodriguez, Pedro L},
	year = {2021},
}

@inproceedings{pennington2014glove,
	title = {{GloVe}: {Global} {Vectors} for {Word} {Representation}},
	doi = {10.3115/v1/D14-1162},
	booktitle = {Proceedings of the 2014 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
	year = {2014},
	pages = {1532--1543},
}

@inproceedings{mikolov2018advances,
	title = {Advances in {Pre}-{Training} {Distributed} {Word} {Representations}},
	url = {https://aclanthology.org/L18-1008},
	booktitle = {Proceedings of the {Eleventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC} 2018)},
	author = {Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
	year = {2018},
	pages = {52--55},
}

@article{laver2003extracting,
	title = {Extracting {Policy} {Positions} from {Political} {Texts} {Using} {Words} as {Data}},
	volume = {97},
	doi = {10.1017/S0003055403000698},
	number = {2},
	journal = {American Political Science Review},
	author = {Laver, Michael and Benoit, Kenneth and Garry, John},
	year = {2003},
	pages = {311--331},
	annote = {Publisher: JSTOR},
}

@inproceedings{kusnerWordEmbeddingsDocument2015,
	title = {From {Word} {Embeddings} {To} {Document} {Distances}},
	url = {https://proceedings.mlr.press/v37/kusnerb15.html},
	abstract = {We present the Word Mover’s Distance (WMD), a novel distance function between text documents. Our work is based on recent results in word embeddings that learn semantically meaningful representations for words from local cooccurrences in sentences. The WMD distance measures the dissimilarity between two text documents as the minimum amount of distance that the embedded words of one document need to “travel” to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover’s Distance, a well studied transportation problem for which several highly efﬁcient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classiﬁcation data sets, in comparison with seven stateof-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor document classiﬁcation error rates.},
	booktitle = {Proceedings of the 32nd {International} {Conference} on {Machine} {Learning}},
	author = {Kusner, Matt J and Sun, Yu and Kolkin, Nicholas I and Weinberger, Kilian Q},
	year = {2015},
	pages = {957--966},
}

@inproceedings{barReflectiveViewText2011,
	title = {A {Reflective} {View} on {Text} {Similarity}},
	url = {https://aclanthology.org/R11-1071},
	abstract = {While the concept of similarity is well grounded in psychology, text similarity is less well-deﬁned. Thus, we analyze text similarity with respect to its deﬁnition and the datasets used for evaluation. We formalize text similarity based on the geometric model of conceptual spaces along three dimensions inherent to texts: structure, style, and content. We empirically ground these dimensions in a set of annotation studies, and categorize applications according to these dimensions. Furthermore, we analyze the characteristics of the existing evaluation datasets, and use those datasets to assess the performance of common text similarity measures.},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} 2011},
	author = {Bar, Daniel and Zesch, Torsten and Gurevych, Iryna},
	year = {2011},
	pages = {515--520},
}

@article{laddUnderstandingUsingCommon2020,
	title = {Understanding and {Using} {Common} {Similarity} {Measures} for {Text} {Analysis}},
	url = {https://programminghistorian.org/en/lessons/common-similarity-measures},
	doi = {10.46430/phen0089},
	number = {9},
	journal = {Programming Historian},
	author = {Ladd, John R.},
	year = {2020},
}

@article{wangMeasurementTextSimilarity2020,
	title = {Measurement of {Text} {Similarity}: {A} {Survey}},
	volume = {11},
	issn = {2078-2489},
	shorttitle = {Measurement of {Text} {Similarity}},
	url = {https://www.mdpi.com/2078-2489/11/9/421},
	doi = {10.3390/info11090421},
	abstract = {Text similarity measurement is the basis of natural language processing tasks, which play an important role in information retrieval, automatic question answering, machine translation, dialogue systems, and document matching. This paper systematically combs the research status of similarity measurement, analyzes the advantages and disadvantages of current methods, develops a more comprehensive classiﬁcation description system of text similarity measurement algorithms, and summarizes the future development direction. With the aim of providing reference for related research and application, the text similarity measurement method is described by two aspects: text distance and text representation. The text distance can be divided into length distance, distribution distance, and semantic distance; text representation is divided into string-based, corpus-based, single-semantic text, multi-semantic text, and graph-structure-based representation. Finally, the development of text similarity is also summarized in the discussion section.},
	language = {en},
	number = {9},
	urldate = {2021-03-20},
	journal = {Information},
	author = {Wang, Jiapeng and Dong, Yihong},
	month = aug,
	year = {2020},
	pages = {421},
}

@misc{siegTextSimilaritiesEstimate2018,
	title = {Text {Similarities} : {Estimate} the degree of similarity between two texts},
	url = {https://medium.com/@adriensieg/text-similarities-da019229c894},
	journal = {Medium},
	author = {Sieg, Adrien},
	year = {2018},
}

@article{hjorthComputersCodersVoters2015,
	title = {Computers, coders, and voters: {Comparing} automated methods for estimating party positions},
	volume = {2},
	issn = {2053-1680},
	doi = {10.1177/2053168015580476},
	number = {2},
	journal = {Research \& Politics},
	author = {Hjorth, Frederik and Klemmensen, Robert and Hobolt, Sara and Hansen, Martin Ejnar and Kurrild-Klitgaard, Peter},
	year = {2015},
	pages = {1--9},
	annote = {Publisher: SAGE Publications Sage UK: London, England},
}

@article{slapinScalingModelEstimating2008,
	title = {A {Scaling} {Model} for {Estimating} {Time}-{Series} {Party} {Positions} from {Texts}},
	volume = {52},
	issn = {0092-5853},
	doi = {10.1111/j.1540-5907.2008.00338.x},
	number = {3},
	journal = {American Journal of Political Science},
	author = {Slapin, Jonathan B and Proksch, Sven‐Oliver},
	year = {2008},
	pages = {705--722},
	annote = {Publisher: Wiley Online Library},
}

@article{welbersTextAnalysis2017,
	title = {Text {Analysis} in {R}},
	volume = {11},
	issn = {1931-2458},
	doi = {10.1080/19312458.2017.1387238},
	number = {4},
	journal = {Communication Methods and Measures},
	author = {Welbers, Kasper and Van Atteveldt, Wouter and Benoit, Kenneth},
	year = {2017},
	pages = {245--265},
	annote = {Publisher: Taylor \& Francis},
}

@book{schutzeIntroductionInformationRetrieval2008,
	address = {New York},
	title = {Introduction to {Information} {Retrieval}},
	isbn = {978-0-521-86571-5},
	publisher = {Cambridge University Press Cambridge},
	author = {Schütze, Hinrich and Manning, Christopher D and Raghavan, Prabhakar},
	year = {2008},
}

@book{kwartlerTextMiningPractice2017,
	address = {Hoboken, NJ},
	title = {Text {Mining} in {Practice} with {R}},
	isbn = {978-1-119-28201-3},
	publisher = {John Wiley \& Sons},
	author = {Kwartler, Ted},
	year = {2017},
}

@incollection{vinczeBeszedEsNyelvelemzo2019,
	address = {Szeged},
	title = {Bevezetés a korpuszok és nyelvi adatbázisok világába},
	isbn = {978-615-5455-93-3},
	booktitle = {Beszéd és nyelvelemző szoftverek a versenyképességért és az esélyegyenlőségért: {HunCLARIN} korpuszok és nyelvtechnológiai eszközök a bölcsészet- és társadalomtudományokban},
	publisher = {SZTE JGYPK Magyar és Alkalmazott Nyelvészeti Tanszék},
	author = {Vincze, Veronika},
	editor = {Sulyok, Hedvig and Juhász, Valéria and Erdei, Tamás},
	year = {2019},
	pages = {5--20},
}

@inproceedings{uvegesNamedEntityRecognition2019,
	title = {Named {Entity} {Recognition} in the {Miskolc} {Legal} {Corpus}},
	url = {https://publicatio.bibl.u-szeged.hu/19233/7/31140948.pdf},
	author = {Üveges, István},
	year = {2019},
	pages = {113--122},
	annote = {ISBN: 963315393X Publisher: Szegedi Tudományegyetem, Informatikai Intézet},
}

@inproceedings{szarvasMultilingualNamedEntity2006,
	title = {A {Multilingual} {Named} {Entity} {Recognition} {System} {Using} {Boosting} and {C4}.5 {Decision} {Tree} {Learning} {Algorithms}},
	doi = {10.1007/11893318_27},
	booktitle = {9th {International} {Conference}, {DS} 2006, {Barcelona}, {Spain}, {October} 7-10, 2006, {Proceedings}},
	publisher = {Springer},
	author = {Szarvas, György and Farkas, Richárd and Kocsor, András},
	year = {2006},
	pages = {267--278},
}

@inproceedings{zsibritaMagyarlancToolMorphological2013,
	title = {magyarlanc: {A} {Toolkit} for {Morphological} and {Dependency} {Parsing} of {Hungarian}},
	url = {https://aclanthology.org/R13-1099},
	booktitle = {Proceedings of the {International} {Conference} {Recent} {Advances} in {Natural} {Language} {Processing} {RANLP} 2013},
	author = {Zsibrita, János and Vincze, Veronika and Farkas, Richárd},
	year = {2013},
	pages = {763--771},
}

@inproceedings{strakaTokenizingPosTagging2017,
	title = {Tokenizing, {POS} {Tagging}, {Lemmatizing} and {Parsing} {UD} 2.0 with {UDPipe}},
	doi = {10.18653/v1/K17-3009},
	booktitle = {Proceedings of the {CoNLL} 2017 {Shared} {Task}: {Multilingual} {Parsing} from {Raw} {Text} to {Universal} {Dependencies}},
	author = {Straka, Milan and Straková, Jana},
	year = {2017},
	pages = {88--99},
}

@article{bradyChallengeBigData2019,
	title = {The {Challenge} of {Big} {Data} and {Data} {Science}},
	volume = {22},
	issn = {1094-2939, 1545-1577},
	url = {https://www.annualreviews.org/doi/10.1146/annurev-polisci-090216-023229},
	doi = {10.1146/annurev-polisci-090216-023229},
	abstract = {Big data and data science are transforming the world in ways that spawn new concerns for social scientists, such as the impacts of the internet on citizens and the media, the repercussions of smart cities, the possibilities of cyber-warfare and cyber-terrorism, the implications of precision medicine, and the consequences of artificial intelligence and automation. Along with these changes in society, powerful new data science methods support research using administrative, internet, textual, and sensor-audio-video data. Burgeoning data and innovative methods facilitate answering previously hard-to-tackle questions about society by offering new ways to form concepts from data, to do descriptive inference, to make causal inferences, and to generate predictions. They also pose challenges as social scientists must grasp the meaning of concepts and predictions generated by convoluted algorithms, weigh the relative value of prediction versus causal inference, and cope with ethical challenges as their methods, such as algorithms for mobilizing voters or determining bail, are adopted by policy makers.},
	language = {en},
	number = {1},
	urldate = {2021-04-15},
	journal = {Annual Review of Political Science},
	author = {Brady, Henry E.},
	year = {2019},
	pages = {297--323},
}

@inproceedings{baccianellaSentiwordnetEnhancedLexical2010,
	title = {{SENTIWORDNET} 3.0: {An} {Enhanced} {Lexical} {Resource} for {Sentiment} {Analysis} and {Opinion} {Mining}},
	url = {http://www.lrec-conf.org/proceedings/lrec2010/pdf/769_Paper.pdf},
	booktitle = {Proceedings of the {Seventh} {International} {Conference} on {Language} {Resources} and {Evaluation} ({LREC}'10)},
	author = {Baccianella, Stefano and Esuli, Andrea and Sebastiani, Fabrizio},
	year = {2010},
	pages = {2200--2204},
	annote = {Issue: 2010},
}

@article{liuSentimentAnalysisSubjectivity2010,
	title = {Sentiment {Analysis} and {Subjectivity}},
	volume = {2},
	url = {https://www.researchgate.net/profile/Bing-Liu-120/publication/228667268_Sentiment_analysis_and_subjectivity/links/5472bbea0cf24bc8ea199f7c/Sentiment-analysis-and-subjectivity.pdf},
	journal = {Handbook of Natural Language Processing},
	author = {Liu, Bing},
	year = {2010},
	pages = {627--666},
}

@book{sebokKvantitativSzovegelemzesEs2016,
	address = {Budapest},
	title = {Kvantitatív szövegelemzés és szövegbányászat a politikatudományban},
	isbn = {978-963-414-229-4},
	publisher = {L'Harmattan},
	editor = {Sebők, Miklós},
	year = {2016},
}

@incollection{balazsFogalmiAlapokEs2016,
	address = {Budapest},
	title = {Fogalmi alapok és a szózsák módszer},
	isbn = {978-963-414-229-4},
	booktitle = {Kvantitatív szövegelemzés és szövegbányászat a politikatudományban},
	publisher = {L'Harmattan},
	author = {Balázs, Ágnes},
	editor = {Sebők, Miklós},
	year = {2016},
	pages = {39--50},
	annote = {Publisher: L’Harmattan Kiadó},
}

@article{sebokMulticlassClassificationNewspaper2021,
	title = {The {Multiclass} {Classification} of {Newspaper} {Articles} with {Machine} {Learning}: {The} {Hybrid} {Binary} {Snowball} {Approach}},
	volume = {29},
	issn = {1047-1987, 1476-4989},
	shorttitle = {The {Multiclass} {Classification} of {Newspaper} {Articles} with {Machine} {Learning}},
	url = {https://www.cambridge.org/core/product/identifier/S1047198720000273/type/journal_article},
	doi = {10.1017/pan.2020.27},
	abstract = {In this article, we present a machine learning-based solution for matching the performance of the gold standard of double-blind human coding when it comes to content analysis in comparative politics. We combine a quantitative text analysis approach with supervised learning and limited human resources in order to classify the front-page articles of a leading Hungarian daily newspaper based on their full text. Our goal was to assign items in our dataset to one of policy topics based on the codebook of the Comparative Agendas Project. The classification of the imbalanced classes of topics was handled by a hybrid binary snowball workflow. This relies on limited human resources as well as supervised learning; it simplifies the multiclass problem to one of binary choice; and it is based on a snowball approach as we augment the training set with machine-classified observations a er each successful round and also between corpora. Our results show that our approach provided better precision results (of over \% for most topic codes) than what is customary for human coders and most computer-assisted coding projects. Nevertheless, this high precision came at the expense of a relatively low, below \%, share of labeled articles.},
	language = {en},
	number = {2},
	urldate = {2021-04-19},
	journal = {Political Analysis},
	author = {Sebők, Miklós and Kacsuk, Zoltán},
	month = apr,
	year = {2021},
	pages = {236--249},
}

@article{sebokViscosityRevisitedPower2021,
	title = {Viscosity {Revisited}: {The} {Power} of {Legislatures} in {New} and {Old} {Democracies} - {A} {Comparative} {Text} {Reuse} {Analysis}},
	author = {Sebők, Miklós and Berki, Tamás and Bolonyai, Flóra},
	year = {2021}
}

@inproceedings{niwattanakulUsingJaccardCoefficient2013,
	title = {Using of {Jaccard} {Coefficient} for {Keywords} {Similarity}},
	url = {https://www.iaeng.org/publication/IMECS2013/IMECS2013_pp380-384.pdf},
	abstract = {Presently, information retrieval can be accomplished simply and rapidly with the use of search engines. This allows users to specify the search criteria as well as specific keywords to obtain the required results. Additionally, an index of search engines has to be updated on most recent information as it is constantly changed over time. Particularly, information retrieval results as documents are typically too extensive, which affect on accessibility of the required results for searchers. Consequently, a similarity measurement between keywords and index terms is essentially performed to facilitate searchers in accessing the required results promptly. Thus, this paper proposed the similarity measurement method between words by deploying Jaccard Coefficient. Technically, we developed a measure of similarity Jaccard with Prolog programming language to compare similarity between sets of data. Furthermore, the performance of this proposed similarity measurement method was accomplished by employing precision, recall, and F-measure. Precisely, the test results demonstrated the awareness of advantage and disadvantages of the measurement which were adapted and applied to a search for meaning by using Jaccard similarity coefficient.},
	booktitle = {Proceedings of the {International} {MultiConference} of {Engineers} and {Computer} {Scientists} 2013 {Vol} {I}, {IMECS} 2013},
	author = {Niwattanakul, Suphakit and Singthongchai, Jatsada and Naenudorn, Ekkachai and Wanapu, Supachanun},
	year = {2013},
	pages = {1--5},
}

@article{benoit2018,
	title = {quanteda: {An} {R} package for the quantitative analysis of textual data},
	volume = {3},
	url = {https://quanteda.io},
	doi = {10.21105/joss.00774},
	number = {30},
	journal = {Journal of Open Source Software},
	author = {Benoit, Kenneth and Watanabe, Kohei and Wang, Haiyan and Nulty, Paul and Obeng, Adam and Müller, Stefan and Matsuo, Akitaka},
	year = {2018},
	pages = {774},
}

@misc{text2vecpackage,
	title = {text2vec: {Modern} {Text} {Mining} {Framework} for {R}},
	url = {https://cran.r-project.org/web/packages/text2vec/index.html},
	author = {Selivanov, Dmitriy and Bickel, Manuel and Wang, Qing},
	year = {2020},
	annote = {R package version 0.6},
}
