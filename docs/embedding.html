<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 Szóbeágyazások | Szövegbányászat és mesterséges intelligencia R-ben</title>
  <meta name="description" content="8 Szóbeágyazások | Szövegbányászat és mesterséges intelligencia R-ben" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="8 Szóbeágyazások | Szövegbányászat és mesterséges intelligencia R-ben" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="8 Szóbeágyazások | Szövegbányászat és mesterséges intelligencia R-ben" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Szóbeágyazások | Szövegbányászat és mesterséges intelligencia R-ben" />
  
  <meta name="twitter:description" content="8 Szóbeágyazások | Szövegbányászat és mesterséges intelligencia R-ben" />
  

<meta name="author" content="Sebők Miklós, Ring Orsolya, Máté Ákos" />


<meta name="date" content="2023-01-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lda_ch.html"/>
<link rel="next" href="scaling.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="konyv_style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Szövegbányászat R-ben</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Üdvözöljük!</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#online-frissítések"><i class="fa fa-check"></i>2.0 - Online frissítések</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Bevezetés</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#a-kötet-témái"><i class="fa fa-check"></i><b>1.1</b> A kötet témái</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#használati-utasítás"><i class="fa fa-check"></i><b>1.2</b> Használati utasítás</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#a-hunminer-használata"><i class="fa fa-check"></i><b>1.3</b> A HunMineR használata</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#handson"><i class="fa fa-check"></i><b>1.4</b> Egy bevezető példa</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#köszönetnyilvánítás"><i class="fa fa-check"></i><b>1.5</b> Köszönetnyilvánítás</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="alapfogalmak.html"><a href="alapfogalmak.html"><i class="fa fa-check"></i><b>2</b> Kulcsfogalmak</a>
<ul>
<li class="chapter" data-level="2.1" data-path="alapfogalmak.html"><a href="alapfogalmak.html#big-data-és-társadalomtudomány"><i class="fa fa-check"></i><b>2.1</b> Big Data és társadalomtudomány</a></li>
<li class="chapter" data-level="2.2" data-path="alapfogalmak.html"><a href="alapfogalmak.html#fogalmi-alapok"><i class="fa fa-check"></i><b>2.2</b> Fogalmi alapok</a></li>
<li class="chapter" data-level="2.3" data-path="alapfogalmak.html"><a href="alapfogalmak.html#a-szövegbányászat-alapelvei"><i class="fa fa-check"></i><b>2.3</b> A szövegbányászat alapelvei</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="adatkezeles.html"><a href="adatkezeles.html"><i class="fa fa-check"></i><b>3</b> Adatkezelés R-ben</a>
<ul>
<li class="chapter" data-level="3.1" data-path="adatkezeles.html"><a href="adatkezeles.html#az-adatok-importálása"><i class="fa fa-check"></i><b>3.1</b> Az adatok importálása</a></li>
<li class="chapter" data-level="3.2" data-path="adatkezeles.html"><a href="adatkezeles.html#az-adatok-exportálása"><i class="fa fa-check"></i><b>3.2</b> Az adatok exportálása</a></li>
<li class="chapter" data-level="3.3" data-path="adatkezeles.html"><a href="adatkezeles.html#a-pipe-operátor"><i class="fa fa-check"></i><b>3.3</b> A pipe operátor</a></li>
<li class="chapter" data-level="3.4" data-path="adatkezeles.html"><a href="adatkezeles.html#műveletek-adattáblákkal"><i class="fa fa-check"></i><b>3.4</b> Műveletek adattáblákkal</a></li>
<li class="chapter" data-level="3.5" data-path="adatkezeles.html"><a href="adatkezeles.html#strings-3"><i class="fa fa-check"></i><b>3.5</b> Munka karakter vektorokkal</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="corpus_ch.html"><a href="corpus_ch.html"><i class="fa fa-check"></i><b>4</b> Korpuszépítés és szövegelőkészítés</a>
<ul>
<li class="chapter" data-level="4.1" data-path="corpus_ch.html"><a href="corpus_ch.html#szövegbeszerzés"><i class="fa fa-check"></i><b>4.1</b> Szövegbeszerzés</a></li>
<li class="chapter" data-level="4.2" data-path="corpus_ch.html"><a href="corpus_ch.html#szövegelőkészítés"><i class="fa fa-check"></i><b>4.2</b> Szövegelőkészítés</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="corpus_ch.html"><a href="corpus_ch.html#tokenizálás-szótövezés-kisbetűsítés-és-a-tiltólistás-szavak-eltávolítása"><i class="fa fa-check"></i><b>4.2.1</b> Tokenizálás, szótövezés, kisbetűsítés és a tiltólistás szavak eltávolítása</a></li>
<li class="chapter" data-level="4.2.2" data-path="corpus_ch.html"><a href="corpus_ch.html#dokumentum-kifejezés-mátrix-dtm-dfm"><i class="fa fa-check"></i><b>4.2.2</b> Dokumentum kifejezés mátrix (dtm, dfm)</a></li>
<li class="chapter" data-level="4.2.3" data-path="corpus_ch.html"><a href="corpus_ch.html#súlyozás"><i class="fa fa-check"></i><b>4.2.3</b> Súlyozás</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="leiro_stat.html"><a href="leiro_stat.html"><i class="fa fa-check"></i><b>5</b> Leíró statisztika</a>
<ul>
<li class="chapter" data-level="5.1" data-path="leiro_stat.html"><a href="leiro_stat.html#szövegek-a-vektortérben"><i class="fa fa-check"></i><b>5.1</b> Szövegek a vektortérben</a></li>
<li class="chapter" data-level="5.2" data-path="leiro_stat.html"><a href="leiro_stat.html#leíró-statisztika"><i class="fa fa-check"></i><b>5.2</b> Leíró statisztika</a></li>
<li class="chapter" data-level="5.3" data-path="leiro_stat.html"><a href="leiro_stat.html#a-szövegek-lexikai-diverzitása"><i class="fa fa-check"></i><b>5.3</b> A szövegek lexikai diverzitása</a></li>
<li class="chapter" data-level="5.4" data-path="leiro_stat.html"><a href="leiro_stat.html#összehasonlításleiro-5"><i class="fa fa-check"></i><b>5.4</b> Összehasonlítás</a></li>
<li class="chapter" data-level="5.5" data-path="leiro_stat.html"><a href="leiro_stat.html#a-kulcsszavak-kontextusa"><i class="fa fa-check"></i><b>5.5</b> A kulcsszavak kontextusa</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="sentiment.html"><a href="sentiment.html"><i class="fa fa-check"></i><b>6</b> Szótárak és érzelemelemzés</a>
<ul>
<li class="chapter" data-level="6.1" data-path="sentiment.html"><a href="sentiment.html#fogalmi-alapok-1"><i class="fa fa-check"></i><b>6.1</b> Fogalmi alapok</a></li>
<li class="chapter" data-level="6.2" data-path="sentiment.html"><a href="sentiment.html#szótárak-az-r-ben"><i class="fa fa-check"></i><b>6.2</b> Szótárak az R-ben</a></li>
<li class="chapter" data-level="6.3" data-path="sentiment.html"><a href="sentiment.html#a-magyar-nemzet-elemzése"><i class="fa fa-check"></i><b>6.3</b> A <em>Magyar Nemzet</em> elemzése</a></li>
<li class="chapter" data-level="6.4" data-path="sentiment.html"><a href="sentiment.html#mnb-sajtóközlemények"><i class="fa fa-check"></i><b>6.4</b> MNB sajtóközlemények</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="lda_ch.html"><a href="lda_ch.html"><i class="fa fa-check"></i><b>7</b> Felügyelet nélküli tanulás</a>
<ul>
<li class="chapter" data-level="7.1" data-path="lda_ch.html"><a href="lda_ch.html#fogalmi-alapok-2"><i class="fa fa-check"></i><b>7.1</b> Fogalmi alapok</a></li>
<li class="chapter" data-level="7.2" data-path="lda_ch.html"><a href="lda_ch.html#k-közép-klaszterezés"><i class="fa fa-check"></i><b>7.2</b> K-közép klaszterezés</a></li>
<li class="chapter" data-level="7.3" data-path="lda_ch.html"><a href="lda_ch.html#lda-topikmodelleklda1"><i class="fa fa-check"></i><b>7.3</b> LDA topikmodellek</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="lda_ch.html"><a href="lda_ch.html#a-vem-módszer-alkalmazása-a-magyar-törvények-korpuszán"><i class="fa fa-check"></i><b>7.3.1</b> A VEM módszer alkalmazása a magyar törvények korpuszán</a></li>
<li class="chapter" data-level="7.3.2" data-path="lda_ch.html"><a href="lda_ch.html#az-lda-gibbs-módszer-alkalmazása-a-magyar-törvények-korpuszán"><i class="fa fa-check"></i><b>7.3.2</b> Az LDA Gibbs módszer alkalmazása a magyar törvények korpuszán</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="lda_ch.html"><a href="lda_ch.html#strukturális-topikmodellek"><i class="fa fa-check"></i><b>7.4</b> Strukturális topikmodellek</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="embedding.html"><a href="embedding.html"><i class="fa fa-check"></i><b>8</b> Szóbeágyazások</a>
<ul>
<li class="chapter" data-level="8.1" data-path="embedding.html"><a href="embedding.html#a-szóbeágyazás-célja"><i class="fa fa-check"></i><b>8.1</b> A szóbeágyazás célja</a></li>
<li class="chapter" data-level="8.2" data-path="embedding.html"><a href="embedding.html#word2vec-és-glove"><i class="fa fa-check"></i><b>8.2</b> Word2Vec és GloVe</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="embedding.html"><a href="embedding.html#glove-használata-magyar-média-korpuszon"><i class="fa fa-check"></i><b>8.2.1</b> GloVe használata magyar média korpuszon</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="scaling.html"><a href="scaling.html"><i class="fa fa-check"></i><b>9</b> Szövegskálázás</a>
<ul>
<li class="chapter" data-level="9.1" data-path="scaling.html"><a href="scaling.html#fogalmi-alapok-3"><i class="fa fa-check"></i><b>9.1</b> Fogalmi alapok</a></li>
<li class="chapter" data-level="9.2" data-path="scaling.html"><a href="scaling.html#wordscores"><i class="fa fa-check"></i><b>9.2</b> Wordscores</a></li>
<li class="chapter" data-level="9.3" data-path="scaling.html"><a href="scaling.html#wordfish"><i class="fa fa-check"></i><b>9.3</b> Wordfish</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="similarity.html"><a href="similarity.html"><i class="fa fa-check"></i><b>10</b> Szövegösszehasonlítás</a>
<ul>
<li class="chapter" data-level="10.1" data-path="similarity.html"><a href="similarity.html#a-szövegösszehasonlítás-különböző-megközelítései"><i class="fa fa-check"></i><b>10.1</b> A szövegösszehasonlítás különböző megközelítései</a></li>
<li class="chapter" data-level="10.2" data-path="similarity.html"><a href="similarity.html#lexikális-hasonlóság"><i class="fa fa-check"></i><b>10.2</b> Lexikális hasonlóság</a></li>
<li class="chapter" data-level="10.3" data-path="similarity.html"><a href="similarity.html#szemantikai-hasonlóság"><i class="fa fa-check"></i><b>10.3</b> Szemantikai hasonlóság</a></li>
<li class="chapter" data-level="10.4" data-path="similarity.html"><a href="similarity.html#hasonlóságszámítás"><i class="fa fa-check"></i><b>10.4</b> Hasonlóságszámítás</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="similarity.html"><a href="similarity.html#adatbázis-importálás-és-előkészítés"><i class="fa fa-check"></i><b>10.4.1</b> Adatbázis-importálás és előkészítés</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="similarity.html"><a href="similarity.html#szövegtisztítás"><i class="fa fa-check"></i><b>10.5</b> Szövegtisztítás</a></li>
<li class="chapter" data-level="10.6" data-path="similarity.html"><a href="similarity.html#a-jaccard-hasonlóság-számítása"><i class="fa fa-check"></i><b>10.6</b> A Jaccard-hasonlóság számítása</a></li>
<li class="chapter" data-level="10.7" data-path="similarity.html"><a href="similarity.html#a-koszinusz-hasonlóság-számítása"><i class="fa fa-check"></i><b>10.7</b> A koszinusz-hasonlóság számítása</a></li>
<li class="chapter" data-level="10.8" data-path="similarity.html"><a href="similarity.html#az-eredmények-vizualizációja"><i class="fa fa-check"></i><b>10.8</b> Az eredmények vizualizációja</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="nlp_ch.html"><a href="nlp_ch.html"><i class="fa fa-check"></i><b>11</b> NLP és névelemfelismerés</a>
<ul>
<li class="chapter" data-level="11.1" data-path="nlp_ch.html"><a href="nlp_ch.html#fogalmi-alapok-4"><i class="fa fa-check"></i><b>11.1</b> Fogalmi alapok</a></li>
<li class="chapter" data-level="11.2" data-path="nlp_ch.html"><a href="nlp_ch.html#a-spacyr-használata"><i class="fa fa-check"></i><b>11.2</b> A <code>spacyr</code> használata</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="nlp_ch.html"><a href="nlp_ch.html#lemmatizálás-tokenizálás-szófaji-egyértelműsítés"><i class="fa fa-check"></i><b>11.2.1</b> Lemmatizálás, tokenizálás, szófaji egyértelműsítés</a></li>
<li class="chapter" data-level="11.2.2" data-path="nlp_ch.html"><a href="nlp_ch.html#saját-.txt-vagy-.csv-fájlokban-elmentett-szövegek-lemmatizálása"><i class="fa fa-check"></i><b>11.2.2</b> Saját <code>.txt</code> vagy <code>.csv</code> fájlokban elmentett szövegek lemmatizálása</a></li>
<li class="chapter" data-level="11.2.3" data-path="nlp_ch.html"><a href="nlp_ch.html#névelemfelismerés-és-eredményeinek-vizualizálása"><i class="fa fa-check"></i><b>11.2.3</b> Névelemfelismerés és eredményeinek vizualizálása</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="felugyelt.html"><a href="felugyelt.html"><i class="fa fa-check"></i><b>12</b> Osztályozás és felügyelt tanulás</a>
<ul>
<li class="chapter" data-level="12.1" data-path="felugyelt.html"><a href="felugyelt.html#basics"><i class="fa fa-check"></i><b>12.1</b> Fogalmi alapok</a></li>
<li class="chapter" data-level="12.2" data-path="felugyelt.html"><a href="felugyelt.html#osztályozás-felügyelt-tanulással"><i class="fa fa-check"></i><b>12.2</b> Osztályozás felügyelt tanulással</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="felugyelt.html"><a href="felugyelt.html#naïve-bayes"><i class="fa fa-check"></i><b>12.2.1</b> Naïve Bayes</a></li>
<li class="chapter" data-level="12.2.2" data-path="felugyelt.html"><a href="felugyelt.html#support-vector-machine"><i class="fa fa-check"></i><b>12.2.2</b> Support-vector machine</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="függelék.html"><a href="függelék.html"><i class="fa fa-check"></i><b>13</b> Függelék</a>
<ul>
<li class="chapter" data-level="13.1" data-path="függelék.html"><a href="függelék.html#az-r-és-az-rstudio-használata"><i class="fa fa-check"></i><b>13.1</b> Az R és az RStudio használata</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="függelék.html"><a href="függelék.html#az-rstudio-kezdőfelülete"><i class="fa fa-check"></i><b>13.1.1</b> Az RStudio kezdőfelülete</a></li>
<li class="chapter" data-level="13.1.2" data-path="függelék.html"><a href="függelék.html#projektmunka"><i class="fa fa-check"></i><b>13.1.2</b> A projektalapú munka</a></li>
<li class="chapter" data-level="13.1.3" data-path="függelék.html"><a href="függelék.html#scriptek-szerkesztése-függvények-használata"><i class="fa fa-check"></i><b>13.1.3</b> Scriptek szerkesztése, függvények használata</a></li>
<li class="chapter" data-level="13.1.4" data-path="függelék.html"><a href="függelék.html#packages"><i class="fa fa-check"></i><b>13.1.4</b> R csomagok</a></li>
<li class="chapter" data-level="13.1.5" data-path="függelék.html"><a href="függelék.html#object"><i class="fa fa-check"></i><b>13.1.5</b> Objektumok tárolása, értékadás</a></li>
<li class="chapter" data-level="13.1.6" data-path="függelék.html"><a href="függelék.html#vector"><i class="fa fa-check"></i><b>13.1.6</b> Vektorok</a></li>
<li class="chapter" data-level="13.1.7" data-path="függelék.html"><a href="függelék.html#faktorok"><i class="fa fa-check"></i><b>13.1.7</b> Faktorok</a></li>
<li class="chapter" data-level="13.1.8" data-path="függelék.html"><a href="függelék.html#data-frame"><i class="fa fa-check"></i><b>13.1.8</b> Data frame</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="függelék.html"><a href="függelék.html#sajat-adat"><i class="fa fa-check"></i><b>13.2</b> Munka saját adatokkal</a></li>
<li class="chapter" data-level="13.3" data-path="függelék.html"><a href="függelék.html#dataviz"><i class="fa fa-check"></i><b>13.3</b> Vizualizáció</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="irodalomjegyzék.html"><a href="irodalomjegyzék.html"><i class="fa fa-check"></i>Irodalomjegyzék</a></li>
<li class="divider"></li>
<li> Sebők Miklós, Ring Orsolya, és Máté Ákos. 2021. Szövegbányászat és Mesterséges Intelligencia R-ben. Budapest: Typotex. </li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Szövegbányászat és mesterséges intelligencia R-ben</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="embedding" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">8</span> Szóbeágyazások<a href="embedding.html#embedding" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="a-szóbeágyazás-célja" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> A szóbeágyazás célja<a href="embedding.html#a-szóbeágyazás-célja" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Az eddigi fejezetekben elsősorban a szózsák (<em>bag of words</em>) alapú módszerek voltak előtérben. A szózsák alapú módszerekkel szemben, amelyek alkalmazása során elveszik a kontextuális tartalom, a szóbeágyazáson (<em>word embedding</em>) alapuló modellek kimondottan a kontextuális információt ragadják meg. A szóbeágyazás a topikmodellekhez hasonlóan a felügyelet nélküli tanulás módszerére épül, azonban itt a dokumentum domináns kifejezéseinek és témáinak feltárása helyett a szavak közötti szemantikai kapcsolat megértése a cél. Vagyis a modellnek képesnek kell lennie az egyes szavak esetén szinonimáik és ellentétpárjaik megtalálására.</p>
<p>A hagyományos topikmodellezés esetén a modell a szavak dokumentumokon belüli együttes megjelenési statisztikái alapján becsül dokumentum-topik, illetve topik-szó eloszlásokat, azzal a céllal, hogy koherens téma-csoportokat képezzen. Ezzel szemben a szóbeágyazás legújabb iskolája már neurális halókon alapul. A neurális háló a tanítási folyamata során az egyes szavak vektorreprezentációját állítja elő. A vektorok jellemzően 100–300 dimenzióból állnak, a távolságuk alapján pedig megállapítható, hogy az egyes kifejezések milyen szemantikai kapcsolatban állnak egymással.</p>
<p>A szóbeágyazás célja tehát a szemantikai relációk feltárása. A szavak vektorizálásának köszönhetően bármely (a korpuszunkban szereplő) tetszőleges számú szóról eldönthetjük, hogy azok milyen szemantikai kapcsolatban állnak egymással, azaz szinonimaként vagy ellentétes fogalompárként szerepelnek. A szóvektorokon dimenziócsökkentő eljárást alkalmazva, s a multidimenzionális (100–300 dimenziós) teret 2 dimenziósra szűkítve könnyen vizualizálhatjuk is a korpuszunk kifejezései között fennálló szemantikai távolságot, és ahogy a lenti ábrákon láthatjuk, azt, hogy az egyes kifejezések milyen relációban állnak egymással – a szemantikailag hasonló tartalmú kifejezések egymáshoz közel, míg a távolabbi jelentéstartalmú kifejezések egymástól távolabb foglalnak helyet. A klasszikus példa, amivel jól lehet szemléltetni a szóvektorok közötti összefüggést: <code>king - man + woman = queen</code>.</p>
</div>
<div id="word2vec-és-glove" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Word2Vec és GloVe<a href="embedding.html#word2vec-és-glove" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A társadalomtudományokban szóbeágyazásra a két legnépszerűbb algoritmus – a Word2Vec és a GloVe – a kontextuális szövegeloszláson (<em>distributional similarity based representations</em>) alapul, vagyis abból a feltevésből indul ki, hogy a hasonló kifejezések hasonló kontextusban fordulnak elő, emellett mindkettő sekély neurális hálón (2 rejtett réteg) alapuló modell.<a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a> A Word2Vec-nek két verziója van: <em>Continuous Bag-of-words</em> (CBOW) és <em>SkipGram</em> (SG). Előbbi a kontextuális szavakból jelzi előre (<em>predicting</em>) a kontextushoz legszorosabban kapcsolódó kifejezést, míg utóbbi adott kifejezésből jelzi előre a kontextust <span class="citation">Mikolov et al. (<a href="irodalomjegyzék.html#ref-mikolov2013efficient">2013</a>)</span>. A GloVe (<em>Global Vectors for Word Representation</em>) a Word2Vec-hez hasonlóan neurális hálón alapuló, szóvektorok előállítását célzó modell, a Word2Vec-kel szemben azonban nem a meghatározott kontextus-ablakban (<em>context window</em>) megjelenő kifejezések közti kapcsolatokat tárja fel, hanem a szöveg globális jellemzőit igyekszik megragadni az egész szöveget jellemző együttes előfordulási gyakoriságok (<em>co-occurrance</em>) meghatározásával <span class="citation">Pennington, Socher, and Manning (<a href="irodalomjegyzék.html#ref-pennington2014glove">2014</a>)</span>. Míg a Word2Vec modell prediktív jellegű, addig a GloVe egy statisztikai alapú (<em>count-based</em>) modell, melyek gyakorlati hasznosításukat tekintve nagyon hasonlóak.</p>
<p>A szóvektor modellek között érdemes megemlíteni a fastText-et is, mely 157 nyelvre (köztük a magyarra is) kínál a szóbeágyazás módszerén alapuló, előre tanított szóvektorokat, melyet tovább lehet tanítani speciális szövegkorpuszokra, ezzel jelentősen lerövidítve a modell tanításához szükséges idő- és kapacitásszükségletet (<span class="citation">Mikolov et al. (<a href="irodalomjegyzék.html#ref-mikolov2018advances">2018</a>)</span>). Habár a GloVe és Word2Vec skip-gram módszerek hasonlóságát a szakirodalom adottnak veszi, a tényleges kép ennél árnyaltabb. A GloVe esetében a ritkán előforduló szavak kisebb súlyt kapnak a szóvektorok számításánál, míg a Word2Vec alulsúlyozza a nagy frekvenciájú szavakat. Ennek a következménye, hogy a Word2Vec esetében gyakori, hogy a szemantikailag legközelebbi szó az egy elütés, nem pedig valid találat. Ennek ellenére a két módszer (amennyiben a Word2Vec algoritmusnál a kisfrekvenciájú tokeneket kiszűrjük) az emberi validálás során nagyon hasonló eredményeket hozott <span class="citation">(<a href="irodalomjegyzék.html#ref-spirlingword">Spirling and Rodriguez 2021</a>)</span>.</p>
<p>A fejezetben a gyakorlati példa során a GloVe algoritmust használjuk majd, mivel véleményünk szerint jobb és könnyebben követhető a dokumentációja az implementációt tartalmazó R csomagnak, mint a többi alternatívának.</p>
<div id="glove-használata-magyar-média-korpuszon" class="section level3 hasAnchor" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> GloVe használata magyar média korpuszon<a href="embedding.html#glove-használata-magyar-média-korpuszon" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Az elemzéshez a <code>text2vec</code> csomagot használjuk, ami a GloVe implementációt tartalmazza <span class="citation">(<a href="irodalomjegyzék.html#ref-text2vecpackage">Selivanov, Bickel, and Wang 2020</a>)</span>. A lenti kód a csomag dokumentáción alapul és a Társadalomtudományi Kutatóközpont által a Hungarian Comparative Agendas Project (CAP) adatbázisában tárolt <em>Magyar Nemzet</em> korpuszt használja.<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a></p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="embedding.html#cb153-1" tabindex="-1"></a><span class="fu">library</span>(text2vec)</span>
<span id="cb153-2"><a href="embedding.html#cb153-2" tabindex="-1"></a><span class="fu">library</span>(quanteda)</span>
<span id="cb153-3"><a href="embedding.html#cb153-3" tabindex="-1"></a><span class="fu">library</span>(quanteda.textstats)</span>
<span id="cb153-4"><a href="embedding.html#cb153-4" tabindex="-1"></a><span class="fu">library</span>(readtext)</span>
<span id="cb153-5"><a href="embedding.html#cb153-5" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb153-6"><a href="embedding.html#cb153-6" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb153-7"><a href="embedding.html#cb153-7" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb153-8"><a href="embedding.html#cb153-8" tabindex="-1"></a><span class="fu">library</span>(stringr)</span>
<span id="cb153-9"><a href="embedding.html#cb153-9" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb153-10"><a href="embedding.html#cb153-10" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb153-11"><a href="embedding.html#cb153-11" tabindex="-1"></a><span class="fu">library</span>(HunMineR)</span></code></pre></div>
<p>A lenti kód blokk azt mutatja be, hogyan kell a betöltött korpuszt tokenizálni és mátrix formátumba alakítani. A korpusz a <em>Magyar Nemzet</em> 2004 és 2014 közötti címlapos cikkeit tartalmazza. Az eddigi előkészítő lépéseket most is megtesszük: kitöröljük a központozást, a számokat, a magyar töltelékszavakat, illetve kisbetűsítünk és eltávolítjuk a felesleges szóközöket és töréseket.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="embedding.html#cb154-1" tabindex="-1"></a>mn <span class="ot">&lt;-</span> HunMineR<span class="sc">::</span>data_magyar_nemzet_large</span>
<span id="cb154-2"><a href="embedding.html#cb154-2" tabindex="-1"></a></span>
<span id="cb154-3"><a href="embedding.html#cb154-3" tabindex="-1"></a>mn_clean <span class="ot">&lt;-</span> mn <span class="sc">%&gt;%</span></span>
<span id="cb154-4"><a href="embedding.html#cb154-4" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb154-5"><a href="embedding.html#cb154-5" tabindex="-1"></a>    <span class="at">text =</span> <span class="fu">str_remove_all</span>(<span class="at">string =</span> text, <span class="at">pattern =</span> <span class="st">&quot;[:cntrl:]&quot;</span>),</span>
<span id="cb154-6"><a href="embedding.html#cb154-6" tabindex="-1"></a>    <span class="at">text =</span> <span class="fu">str_remove_all</span>(<span class="at">string =</span> text, <span class="at">pattern =</span> <span class="st">&quot;[:punct:]&quot;</span>),</span>
<span id="cb154-7"><a href="embedding.html#cb154-7" tabindex="-1"></a>    <span class="at">text =</span> <span class="fu">str_remove_all</span>(<span class="at">string =</span> text, <span class="at">pattern =</span> <span class="st">&quot;[:digit:]&quot;</span>),</span>
<span id="cb154-8"><a href="embedding.html#cb154-8" tabindex="-1"></a>    <span class="at">text =</span> <span class="fu">str_to_lower</span>(text),</span>
<span id="cb154-9"><a href="embedding.html#cb154-9" tabindex="-1"></a>    <span class="at">text =</span> <span class="fu">str_trim</span>(text),</span>
<span id="cb154-10"><a href="embedding.html#cb154-10" tabindex="-1"></a>    <span class="at">text =</span> <span class="fu">str_squish</span>(text)</span>
<span id="cb154-11"><a href="embedding.html#cb154-11" tabindex="-1"></a>  )</span></code></pre></div>
<p>A <code>glimpse</code> funkció segítségével belepillanthatunk mind a két korpuszba és láthatjuk, hogy sikeres volt a tisztítása, valamint azt is, hogy jelenleg egyetlen metaadatunk a dokumentumok azonosítója.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="embedding.html#cb155-1" tabindex="-1"></a><span class="fu">glimpse</span>(mn)</span>
<span id="cb155-2"><a href="embedding.html#cb155-2" tabindex="-1"></a><span class="co">#&gt; Rows: 35,021</span></span>
<span id="cb155-3"><a href="embedding.html#cb155-3" tabindex="-1"></a><span class="co">#&gt; Columns: 2</span></span>
<span id="cb155-4"><a href="embedding.html#cb155-4" tabindex="-1"></a><span class="co">#&gt; $ doc_id &lt;chr&gt; &quot;mn_2002_05_27_00.txt&quot;, &quot;mn_2002_05_27_01.txt&quot;, &quot;mn_2002_…</span></span>
<span id="cb155-5"><a href="embedding.html#cb155-5" tabindex="-1"></a><span class="co">#&gt; $ text   &lt;chr&gt; &quot;Csere szerb módra\nNagy vihart kavart Szerbiában a kormá…</span></span>
<span id="cb155-6"><a href="embedding.html#cb155-6" tabindex="-1"></a><span class="fu">glimpse</span>(mn_clean)</span>
<span id="cb155-7"><a href="embedding.html#cb155-7" tabindex="-1"></a><span class="co">#&gt; Rows: 35,021</span></span>
<span id="cb155-8"><a href="embedding.html#cb155-8" tabindex="-1"></a><span class="co">#&gt; Columns: 2</span></span>
<span id="cb155-9"><a href="embedding.html#cb155-9" tabindex="-1"></a><span class="co">#&gt; $ doc_id &lt;chr&gt; &quot;mn_2002_05_27_00.txt&quot;, &quot;mn_2002_05_27_01.txt&quot;, &quot;mn_2002_…</span></span>
<span id="cb155-10"><a href="embedding.html#cb155-10" tabindex="-1"></a><span class="co">#&gt; $ text   &lt;chr&gt; &quot;csere szerb módranagy vihart kavart szerbiában a kormány…</span></span></code></pre></div>
<p>Fontos különbség, hogy az eddigi munkafolyamatokkal ellentétben a GloVe algoritmus nem egy dokumentum-kifejezés mátrixon dolgozik, hanem egy kifejezések együttes előfordulását tartalmazó mátrixot (<em>feature co-occurence matrix</em>) kell készíteni inputként. Ezt a <code>quanteda</code> <code>fcm()</code> függvényével tudjuk előállítani, ami a tokenekből készíti el a mátrixot. A tokenek sorrendiségét úgy tudjuk megőrizni, hogy egy <code>dfm</code> objektumból csak a kifejezéseket tartjuk meg a <code>featnames()</code> függvény segítségével, majd a teljes token halmazból a <code>tokens_select()</code> függvénnyel kiválasztjuk őket.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="embedding.html#cb156-1" tabindex="-1"></a>mn_corpus <span class="ot">&lt;-</span> <span class="fu">corpus</span>(mn_clean)</span>
<span id="cb156-2"><a href="embedding.html#cb156-2" tabindex="-1"></a></span>
<span id="cb156-3"><a href="embedding.html#cb156-3" tabindex="-1"></a>mn_tokens <span class="ot">&lt;-</span> <span class="fu">tokens</span>(mn_corpus) <span class="sc">%&gt;%</span></span>
<span id="cb156-4"><a href="embedding.html#cb156-4" tabindex="-1"></a>  <span class="fu">tokens_remove</span>(<span class="fu">stopwords</span>(<span class="at">language =</span> <span class="st">&quot;hungarian&quot;</span>))</span>
<span id="cb156-5"><a href="embedding.html#cb156-5" tabindex="-1"></a></span>
<span id="cb156-6"><a href="embedding.html#cb156-6" tabindex="-1"></a>features <span class="ot">&lt;-</span> <span class="fu">dfm</span>(mn_tokens) <span class="sc">%&gt;%</span></span>
<span id="cb156-7"><a href="embedding.html#cb156-7" tabindex="-1"></a>  <span class="fu">dfm_trim</span>(<span class="at">min_termfreq =</span> <span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb156-8"><a href="embedding.html#cb156-8" tabindex="-1"></a>  quanteda<span class="sc">::</span><span class="fu">featnames</span>()</span>
<span id="cb156-9"><a href="embedding.html#cb156-9" tabindex="-1"></a></span>
<span id="cb156-10"><a href="embedding.html#cb156-10" tabindex="-1"></a>mn_tokens <span class="ot">&lt;-</span> <span class="fu">tokens_select</span>(mn_tokens, features, <span class="at">padding =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Az <code>fcm</code> megalkotása során a célkifejezéstől való távolság függvényében súlyozzuk a tokeneket.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="embedding.html#cb157-1" tabindex="-1"></a>mn_fcm <span class="ot">&lt;-</span> quanteda<span class="sc">::</span><span class="fu">fcm</span>(mn_tokens, <span class="at">context =</span> <span class="st">&quot;window&quot;</span>, <span class="at">count =</span> <span class="st">&quot;weighted&quot;</span>, <span class="at">weights =</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>), <span class="at">tri =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>A tényleges szóbeágyazás a <code>text2vec</code> csomaggal történik. A <code>GlobalVector</code> egy új „környezetet” (<em>environment</em>) hoz létre. Itt adhatjuk meg az alapvető paramétereket. A <code>rank</code> a vektor dimenziót adja meg (a szakirodalomban a 300–500 dimenzió a megszokott). A többi paraméterrel is lehet kísérletezni, hogy mennyire változtatja meg a kapott szóbeágyazásokat. A <code>fit_transform</code> pedig a tényleges becslést végzi. Itt az iterációk számát (a gépi tanulásos irodalomban <em>epoch</em>-nak is hívják a tanulási köröket) és a korai leállás (<em>early stopping</em>) kritériumát a <code>convergence_tol</code> megadásával állíthatjuk be. Minél több dimenziót szeretnénk és minél több iterációt, annál tovább fog tartani a szóbeágyazás futtatása.</p>
<p>Az egyszerűség és a gyorsaság miatt a lenti kód 10 körös tanulást ad meg, ami a relatíve kicsi <em>Magyar Nemzet</em> korpuszon ~3 perc alatt fut le.<a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a> Természetesen minél nagyobb korpuszon, minél több iterációt futtatunk, annál pontosabb eredményt fogunk kapni. A <code>text2vec</code> csomag képes a számítások párhuzamosítására, így alapbeállításként a rendelkezésre álló összes CPU magot teljesen kihasználja a számításhoz. Ennek ellenére egy százezres, milliós korpusz esetén több óra is lehet a tanítás.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="embedding.html#cb158-1" tabindex="-1"></a>glove <span class="ot">&lt;-</span> GlobalVectors<span class="sc">$</span><span class="fu">new</span>(<span class="at">rank =</span> <span class="dv">300</span>, <span class="at">x_max =</span> <span class="dv">10</span>, <span class="at">learning_rate =</span> <span class="fl">0.1</span>)</span>
<span id="cb158-2"><a href="embedding.html#cb158-2" tabindex="-1"></a></span>
<span id="cb158-3"><a href="embedding.html#cb158-3" tabindex="-1"></a>mn_main <span class="ot">&lt;-</span> glove<span class="sc">$</span><span class="fu">fit_transform</span>(mn_fcm, <span class="at">n_iter =</span> <span class="dv">10</span>, <span class="at">convergence_tol =</span> <span class="fl">0.1</span>)</span>
<span id="cb158-4"><a href="embedding.html#cb158-4" tabindex="-1"></a><span class="co">#&gt; INFO  [13:19:48.862] epoch 1, loss 0.2291</span></span>
<span id="cb158-5"><a href="embedding.html#cb158-5" tabindex="-1"></a><span class="co">#&gt; INFO  [13:20:14.583] epoch 2, loss 0.0963</span></span>
<span id="cb158-6"><a href="embedding.html#cb158-6" tabindex="-1"></a><span class="co">#&gt; INFO  [13:20:34.354] epoch 3, loss 0.0706</span></span>
<span id="cb158-7"><a href="embedding.html#cb158-7" tabindex="-1"></a><span class="co">#&gt; INFO  [13:20:52.810] epoch 4, loss 0.0490</span></span>
<span id="cb158-8"><a href="embedding.html#cb158-8" tabindex="-1"></a><span class="co">#&gt; INFO  [13:21:11.203] epoch 5, loss 0.0412</span></span>
<span id="cb158-9"><a href="embedding.html#cb158-9" tabindex="-1"></a><span class="co">#&gt; INFO  [13:21:29.323] epoch 6, loss 0.0362</span></span>
<span id="cb158-10"><a href="embedding.html#cb158-10" tabindex="-1"></a><span class="co">#&gt; INFO  [13:21:45.562] epoch 7, loss 0.0326</span></span>
<span id="cb158-11"><a href="embedding.html#cb158-11" tabindex="-1"></a><span class="co">#&gt; INFO  [13:22:03.680] epoch 8, loss 0.0298</span></span>
<span id="cb158-12"><a href="embedding.html#cb158-12" tabindex="-1"></a><span class="co">#&gt; INFO  [13:22:03.681] Success: early stopping. Improvement at iterartion 8 is less then convergence_tol</span></span></code></pre></div>
<p>A végleges szóvektorokat a becslés során elkészült két mátrix összegeként kapjuk.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="embedding.html#cb159-1" tabindex="-1"></a>mn_context <span class="ot">&lt;-</span> glove<span class="sc">$</span>components</span>
<span id="cb159-2"><a href="embedding.html#cb159-2" tabindex="-1"></a></span>
<span id="cb159-3"><a href="embedding.html#cb159-3" tabindex="-1"></a>mn_word_vectors <span class="ot">&lt;-</span> mn_main <span class="sc">+</span> <span class="fu">t</span>(mn_context)</span></code></pre></div>
<p>Az egyes szavakhoz legközelebb álló szavakat a koszinusz hasonlóság alapján kapjuk, a <code>sim2()</code> függvénnyel. A lenti példában „l2” normalizálást alkalmazunk, majd a kapott hasonlósági vektort csökkenő sorrendbe rendezzük. Példaként a „polgármester” szónak a környezetét nézzük meg. Mivel a korpuszunk egy politikai napilap, ezért nem meglepő, hogy a legközelebbi szavak a politikához kapcsolódnak.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="embedding.html#cb160-1" tabindex="-1"></a>teszt <span class="ot">&lt;-</span> mn_word_vectors[<span class="st">&quot;polgármester&quot;</span>, , drop <span class="ot">=</span> F]</span>
<span id="cb160-2"><a href="embedding.html#cb160-2" tabindex="-1"></a></span>
<span id="cb160-3"><a href="embedding.html#cb160-3" tabindex="-1"></a>cos_sim_rom <span class="ot">&lt;-</span> text2vec<span class="sc">::</span><span class="fu">sim2</span>(<span class="at">x =</span> mn_word_vectors, <span class="at">y =</span> teszt, <span class="at">method =</span> <span class="st">&quot;cosine&quot;</span>, <span class="at">norm =</span> <span class="st">&quot;l2&quot;</span>)</span>
<span id="cb160-4"><a href="embedding.html#cb160-4" tabindex="-1"></a></span>
<span id="cb160-5"><a href="embedding.html#cb160-5" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(cos_sim_rom[, <span class="dv">1</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>), <span class="dv">5</span>)</span>
<span id="cb160-6"><a href="embedding.html#cb160-6" tabindex="-1"></a><span class="co">#&gt; polgármester        mszps  szocialista     fideszes    politikus </span></span>
<span id="cb160-7"><a href="embedding.html#cb160-7" tabindex="-1"></a><span class="co">#&gt;        1.000        0.519        0.508        0.465        0.409</span></span></code></pre></div>
<p>A lenti <code>show_vector()</code> függvényt definiálva a kapott eredmény egy data frame lesz, és az <code>n</code> változtatásával a kapcsolódó szavak számát is könnyen változtathatjuk.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="embedding.html#cb161-1" tabindex="-1"></a>show_vector <span class="ot">&lt;-</span> <span class="cf">function</span>(vectors, pattern, <span class="at">n =</span> <span class="dv">5</span>) {</span>
<span id="cb161-2"><a href="embedding.html#cb161-2" tabindex="-1"></a>  term <span class="ot">&lt;-</span> mn_word_vectors[pattern, , drop <span class="ot">=</span> F]</span>
<span id="cb161-3"><a href="embedding.html#cb161-3" tabindex="-1"></a>  cos_sim <span class="ot">&lt;-</span> <span class="fu">sim2</span>(<span class="at">x =</span> vectors, <span class="at">y =</span> term, <span class="at">method =</span> <span class="st">&quot;cosine&quot;</span>, <span class="at">norm =</span> <span class="st">&quot;l2&quot;</span>)</span>
<span id="cb161-4"><a href="embedding.html#cb161-4" tabindex="-1"></a>  cos_sim_head <span class="ot">&lt;-</span> <span class="fu">head</span>(<span class="fu">sort</span>(cos_sim[, <span class="dv">1</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>), n)</span>
<span id="cb161-5"><a href="embedding.html#cb161-5" tabindex="-1"></a>  output <span class="ot">&lt;-</span> <span class="fu">enframe</span>(cos_sim_head, <span class="at">name =</span> <span class="st">&quot;term&quot;</span>, <span class="at">value =</span> <span class="st">&quot;dist&quot;</span>)</span>
<span id="cb161-6"><a href="embedding.html#cb161-6" tabindex="-1"></a>  <span class="fu">return</span>(output)</span>
<span id="cb161-7"><a href="embedding.html#cb161-7" tabindex="-1"></a>}</span></code></pre></div>
<p>Példánkban láthatjuk, hogy a „barack” szó beágyazásának eredménye nem gyümölcsöt fog adni, hanem az Egyesült Államok elnökét és a hozzá kapcsolódó szavakat.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="embedding.html#cb162-1" tabindex="-1"></a><span class="fu">show_vector</span>(mn_word_vectors, <span class="st">&quot;barack&quot;</span>, <span class="dv">10</span>)</span>
<span id="cb162-2"><a href="embedding.html#cb162-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 2</span></span>
<span id="cb162-3"><a href="embedding.html#cb162-3" tabindex="-1"></a><span class="co">#&gt;   term          dist</span></span>
<span id="cb162-4"><a href="embedding.html#cb162-4" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;        &lt;dbl&gt;</span></span>
<span id="cb162-5"><a href="embedding.html#cb162-5" tabindex="-1"></a><span class="co">#&gt; 1 barack       1    </span></span>
<span id="cb162-6"><a href="embedding.html#cb162-6" tabindex="-1"></a><span class="co">#&gt; 2 obama        0.726</span></span>
<span id="cb162-7"><a href="embedding.html#cb162-7" tabindex="-1"></a><span class="co">#&gt; 3 amerikai     0.429</span></span>
<span id="cb162-8"><a href="embedding.html#cb162-8" tabindex="-1"></a><span class="co">#&gt; 4 elnök        0.394</span></span>
<span id="cb162-9"><a href="embedding.html#cb162-9" tabindex="-1"></a><span class="co">#&gt; 5 demokrata    0.389</span></span>
<span id="cb162-10"><a href="embedding.html#cb162-10" tabindex="-1"></a><span class="co">#&gt; 6 republikánus 0.282</span></span>
<span id="cb162-11"><a href="embedding.html#cb162-11" tabindex="-1"></a><span class="co">#&gt; # ℹ 4 more rows</span></span></code></pre></div>
<p>Ugyanez működik magyar vezetőkkel is.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="embedding.html#cb163-1" tabindex="-1"></a><span class="fu">show_vector</span>(mn_word_vectors, <span class="st">&quot;orbán&quot;</span>, <span class="dv">10</span>)</span>
<span id="cb163-2"><a href="embedding.html#cb163-2" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 2</span></span>
<span id="cb163-3"><a href="embedding.html#cb163-3" tabindex="-1"></a><span class="co">#&gt;   term            dist</span></span>
<span id="cb163-4"><a href="embedding.html#cb163-4" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb163-5"><a href="embedding.html#cb163-5" tabindex="-1"></a><span class="co">#&gt; 1 orbán          1.00 </span></span>
<span id="cb163-6"><a href="embedding.html#cb163-6" tabindex="-1"></a><span class="co">#&gt; 2 viktor         0.932</span></span>
<span id="cb163-7"><a href="embedding.html#cb163-7" tabindex="-1"></a><span class="co">#&gt; 3 miniszterelnök 0.764</span></span>
<span id="cb163-8"><a href="embedding.html#cb163-8" tabindex="-1"></a><span class="co">#&gt; 4 mondta         0.699</span></span>
<span id="cb163-9"><a href="embedding.html#cb163-9" tabindex="-1"></a><span class="co">#&gt; 5 kormányfő      0.686</span></span>
<span id="cb163-10"><a href="embedding.html#cb163-10" tabindex="-1"></a><span class="co">#&gt; 6 fidesz         0.675</span></span>
<span id="cb163-11"><a href="embedding.html#cb163-11" tabindex="-1"></a><span class="co">#&gt; # ℹ 4 more rows</span></span></code></pre></div>
<p>A szakirodalomban klasszikus vektorműveletes példákat is reprokuálni tudjuk a <em>Magyar Nemzet</em> korpuszon készített szóbeágyazásainkkal. A <code>budapest - magyarország + német + németország</code> eredményét úgy kapjuk meg, hogy az egyes szavakhoz tartozó vektorokat kivonjuk egymásból, illetve hozzáadjuk őket, ezután pedig a kapott mátrixon a <code>quanteda</code> csomag <code>textstat_simil()</code> függvényével kiszámítjuk az új hasonlósági értékeket.</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="embedding.html#cb164-1" tabindex="-1"></a>budapest <span class="ot">&lt;-</span> mn_word_vectors[<span class="st">&quot;budapest&quot;</span>, , drop <span class="ot">=</span> <span class="cn">FALSE</span>] <span class="sc">-</span> mn_word_vectors[<span class="st">&quot;magyarország&quot;</span>, , drop <span class="ot">=</span> <span class="cn">FALSE</span>] <span class="sc">+</span> mn_word_vectors[<span class="st">&quot;német&quot;</span>, , drop <span class="ot">=</span> <span class="cn">FALSE</span>] <span class="sc">+</span></span>
<span id="cb164-2"><a href="embedding.html#cb164-2" tabindex="-1"></a>  <span class="sc">+</span> mn_word_vectors[<span class="st">&quot;németország&quot;</span>, , drop <span class="ot">=</span> <span class="cn">FALSE</span>]</span>
<span id="cb164-3"><a href="embedding.html#cb164-3" tabindex="-1"></a></span>
<span id="cb164-4"><a href="embedding.html#cb164-4" tabindex="-1"></a>cos_sim <span class="ot">&lt;-</span> <span class="fu">textstat_simil</span>(<span class="at">x =</span> <span class="fu">as.dfm</span>(mn_word_vectors), <span class="at">y =</span> <span class="fu">as.dfm</span>(budapest), <span class="at">method =</span> <span class="st">&quot;cosine&quot;</span>)</span>
<span id="cb164-5"><a href="embedding.html#cb164-5" tabindex="-1"></a></span>
<span id="cb164-6"><a href="embedding.html#cb164-6" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">sort</span>(cos_sim[, <span class="dv">1</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>), <span class="dv">5</span>)</span>
<span id="cb164-7"><a href="embedding.html#cb164-7" tabindex="-1"></a><span class="co">#&gt;    budapest németország       német     airport   kancellár </span></span>
<span id="cb164-8"><a href="embedding.html#cb164-8" tabindex="-1"></a><span class="co">#&gt;       0.602       0.557       0.537       0.422       0.394</span></span></code></pre></div>
<p>A szavak egymástól való távolságát vizuálisan is tudjuk ábrázolni. Az egyik ezzel kapcsolatban felmerülő probléma, hogy egy 2 dimenziós ábrán akarunk egy 3–500 dimenziós mátrixot ábrázolni. Több lehetséges megoldás is van, mi ezek közül a lehető legegyszerűbbet mutatjuk be.<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a> Első lépésben egy data frame-et készítünk a szóbeágyazás eredményeként kapott mátrixból, megtartva a szavakat az első oszlopban a <code>tibble</code> csomag <code>rownames_to_column()</code> függvényével. Mivel csak 2 dimenziót tudunk ábrázolni egy tradícionális statikus ábrán, ezért a <code>V1</code> és <code>V2</code> oszlopokat tartjuk csak meg, amik az első és második dimenziót reprezentálják.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="embedding.html#cb165-1" tabindex="-1"></a>mn_embedding_df <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(mn_word_vectors[, <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)]) <span class="sc">%&gt;%</span> </span>
<span id="cb165-2"><a href="embedding.html#cb165-2" tabindex="-1"></a>  tibble<span class="sc">::</span><span class="fu">rownames_to_column</span>(<span class="at">var =</span> <span class="st">&quot;words&quot;</span>)</span></code></pre></div>
<p>Ezután pedig a <code>ggplot()</code> függvényt felhasználva definiálunk egy új, <code>embedding_plot()</code> nevű, függvényt, ami az elkészült data frame alapján bármilyen kulcsszó kombinációt képes ábrázolni.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="embedding.html#cb166-1" tabindex="-1"></a>embedding_plot <span class="ot">&lt;-</span> <span class="cf">function</span>(data, keywords) {</span>
<span id="cb166-2"><a href="embedding.html#cb166-2" tabindex="-1"></a>  data <span class="sc">%&gt;%</span> </span>
<span id="cb166-3"><a href="embedding.html#cb166-3" tabindex="-1"></a>    <span class="fu">filter</span>(words <span class="sc">%in%</span> keywords) <span class="sc">%&gt;%</span> </span>
<span id="cb166-4"><a href="embedding.html#cb166-4" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(V1, V2, <span class="at">label =</span> words)) <span class="sc">+</span></span>
<span id="cb166-5"><a href="embedding.html#cb166-5" tabindex="-1"></a>    <span class="fu">labs</span>(</span>
<span id="cb166-6"><a href="embedding.html#cb166-6" tabindex="-1"></a>      <span class="at">x =</span> <span class="st">&quot;Első dimenzió&quot;</span>,</span>
<span id="cb166-7"><a href="embedding.html#cb166-7" tabindex="-1"></a>      <span class="at">y =</span> <span class="st">&quot;Második dimenzió&quot;</span></span>
<span id="cb166-8"><a href="embedding.html#cb166-8" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb166-9"><a href="embedding.html#cb166-9" tabindex="-1"></a>    <span class="fu">geom_text</span>() <span class="sc">+</span></span>
<span id="cb166-10"><a href="embedding.html#cb166-10" tabindex="-1"></a>    <span class="fu">xlim</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb166-11"><a href="embedding.html#cb166-11" tabindex="-1"></a>    <span class="fu">ylim</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb166-12"><a href="embedding.html#cb166-12" tabindex="-1"></a>}</span></code></pre></div>
<p>Példaként néhány településnevet megvizsgálva, azt látjuk, hogy a megadott szavak, jelen esetben “budapest”, “debrecen”, “washington”, “moszkva” milyen közel vagy távol vannak egymástól, vagyis milyen gyakorisággal fordulnak elő ugyanazon szavak társaságában. A magyar városok közel helyezkednek el egymáshoz, ám “washington” és “moszkva” távolsága nagyobb. Ennek az oka az lehet hogy a két magyar nagyváros gyakrabban szerepel hasonló kontextusban a belföldi hírekben, míg a két külföldi főváros valószínűleg eltérő külpolitikai környezetben jelenik meg.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="embedding.html#cb167-1" tabindex="-1"></a>words_selected <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;moszkva&quot;</span>, <span class="st">&quot;debrecen&quot;</span>, <span class="st">&quot;budapest&quot;</span>, <span class="st">&quot;washington&quot;</span>)</span>
<span id="cb167-2"><a href="embedding.html#cb167-2" tabindex="-1"></a></span>
<span id="cb167-3"><a href="embedding.html#cb167-3" tabindex="-1"></a>embedded <span class="ot">&lt;-</span> <span class="fu">embedding_plot</span>(<span class="at">data =</span> mn_embedding_df, <span class="at">keywords =</span> words_selected)</span>
<span id="cb167-4"><a href="embedding.html#cb167-4" tabindex="-1"></a></span>
<span id="cb167-5"><a href="embedding.html#cb167-5" tabindex="-1"></a><span class="fu">ggplotly</span>(embedded)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:embedding"></span>
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-fbffef0676c26e1b513c" style="width:90%;height:600px;"></div>
<script type="application/json" data-for="htmlwidget-fbffef0676c26e1b513c">{"x":{"data":[{"x":[-0.247718246207351,-0.26213173993172,0.0137705472541759,-0.065452029590112],"y":[-0.219731949520028,-0.0285974462457212,0.0902905984164025,-0.142999626232075],"text":["washington","budapest","moszkva","debrecen"],"hovertext":["V1: -0.2477<br />V2: -0.2197<br />words: washington","V1: -0.2621<br />V2: -0.0286<br />words: budapest","V1:  0.0138<br />V2:  0.0903<br />words: moszkva","V1: -0.0655<br />V2: -0.1430<br />words: debrecen"],"textfont":{"size":14.6645669291339,"color":"rgba(0,0,0,1)"},"type":"scatter","mode":"text","hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":41.5707762557078,"r":7.30593607305936,"b":55.5251141552512,"l":48.9497716894977},"plot_bgcolor":"rgba(255,255,255,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-1.1,1.1],"tickmode":"array","ticktext":["-1.0","-0.5","0.0","0.5","1.0"],"tickvals":[-1,-0.5,0,0.5,1],"categoryorder":"array","categoryarray":["-1.0","-0.5","0.0","0.5","1.0"],"nticks":null,"ticks":"outside","tickcolor":"rgba(179,179,179,1)","ticklen":3.65296803652968,"tickwidth":0.33208800332088,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(222,222,222,1)","gridwidth":0.33208800332088,"zeroline":false,"anchor":"y","title":{"text":"Első dimenzió","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-1.1,1.1],"tickmode":"array","ticktext":["-1.0","-0.5","0.0","0.5","1.0"],"tickvals":[-1,-0.5,0,0.5,1],"categoryorder":"array","categoryarray":["-1.0","-0.5","0.0","0.5","1.0"],"nticks":null,"ticks":"outside","tickcolor":"rgba(179,179,179,1)","ticklen":3.65296803652968,"tickwidth":0.33208800332088,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(222,222,222,1)","gridwidth":0.33208800332088,"zeroline":false,"anchor":"x","title":{"text":"Második dimenzió","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":"transparent","line":{"color":"rgba(179,179,179,1)","width":0.66417600664176,"linetype":"solid"},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"b19038ca299a":{"x":{},"y":{},"label":{},"type":"scatter"}},"cur_data":"b19038ca299a","visdat":{"b19038ca299a":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Ábra 8.1: Kiválasztott szavak két dimenzós térben
</p>
</div>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="43">
<li id="fn43"><p>Egy kiváló tanulmányban <span class="citation">Spirling and Rodriguez (<a href="irodalomjegyzék.html#ref-spirlingword">2021</a>)</span> (könyvünk írásakor még nem jelent meg) összehasonlítják a Word2Vec és GloVe módszereket, különböző paraméterekkel, adatbázisokkal. Azoknak, akiket komolyabban érdekelnek a szóbeágyazás gyakorlati alkalmazásának a részletei, mindenképp ajánljuk elolvasásra.<a href="embedding.html#fnref43" class="footnote-back">↩︎</a></p></li>
<li id="fn44"><p>A Magyar CAP Project által kezelt adatbázisok regisztrációt követően elérhetőek az elábbi linken: <a href="https://cap.tk.hu/adatbazisok">https://cap.tk.hu/adatbazisok</a>. A <code>text2vec</code> csomag dokumentációja: <a href="https://cran.r-project.org/web/packages/text2vec/vignettes/glove.html">https://cran.r-project.org/web/packages/text2vec/vignettes/glove.html</a><a href="embedding.html#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>A futtatásra használt PC konfiguráció: CPU: Intel Core i5-4460 (3.2GHz); RAM: 16GB<a href="embedding.html#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>Az egyik legelterjedtebb dimenzionalitás csökkentő eljárás a szakirodalomban a főkomponens-analízis (<em>principal component analysis</em>), illetve szintén gyakran használt az irodalomban az úgynevezett t-SNE (<em>t-distributed stochastic neighbor embedding</em>).<a href="embedding.html#fnref46" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lda_ch.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="scaling.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
